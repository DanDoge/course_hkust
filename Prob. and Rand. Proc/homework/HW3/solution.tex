\documentclass[12pt,letterpaper]{article}
\usepackage[top=2cm, bottom=4.5cm, left=2.5cm, right=2.5cm]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{pgfplots}
\pgfplotsset{width=15cm}

\hypersetup{%
  colorlinks=true,
  linkcolor=blue,
  linkbordercolor={0 0 1}
}

\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}

% Edit these as appropriate
\newcommand\course{ELEC 2600}
\newcommand\hwnumber{3}                  % <-- homework number
\newcommand\NetIDa{Huang Daoji}           % <-- NetID of person #1
\newcommand\NetIDb{20623420}

\pagestyle{fancyplain}
\headheight 35pt
\lhead{\NetIDa \\ \NetIDb}
\chead{\textbf{\Large Homework \hwnumber}}
\rhead{\course \\ \today}
\lfoot{}
\cfoot{}
\rfoot{\small\thepage}
\headsep 1.5em

\begin{document}

\section*{Problem 1}
    \subsection*{a}
        From the joint pmf, we have
        \begin{equation*}
            \begin{aligned}
                c + 0.1 + 0.1 + 0.2 + 0.1 + 0.2 + 0.1 + 0.1 &= 1 \\
                c &= 0.1 \\
            \end{aligned}
        \end{equation*}
    \subsection*{b}
        From definition of joint cdf, $F_{XY}(2, 1)$ will be
        \begin{equation*}
            \begin{aligned}
                F_{XY}(2, 1) &=  \sum_{x \leq 2,\ y \leq 1} p_{XY}(j, k) \\
                &= 0.1 + 0.1 + 0.2 + 0.1 \\
                &= 0.5 \\
            \end{aligned}
        \end{equation*}
    \subsection*{c}
        From the table of pmf, by summing up the $p_{XY}(j, k)$ in each row / column, we have
        \begin{center}
            \begin{tabular}{| c | c | c | c | c | c |}
                \hline
                $j$  & 1 & 2 & 3 & 4 & otherwise\\
                \hline
                $P_{X}(j)$ & 0.3 & 0.3 & 0.2 & 0.2 & 0 \\
                \hline
            \end{tabular}
        \end{center}
        \begin{center}
            \begin{tabular}{| c | c | c | c | c |}
                \hline
                $k$  & 0 & 1 & 2 & otherwise\\
                \hline
                $P_{Y}(k)$ & 0.3 & 0.5 & 0.2 & 0 \\
                \hline
            \end{tabular}
        \end{center}
    \subsection*{d}
        No, a counterexample would be $(4, 1)$, where $P_{XY}(4, 1) \not= P_{X}(4) \times P_{Y}(1)$
    \subsection*{e}
        Yes, by calculating the covarience of $X, Y$, we have
        \begin{equation*}
            \begin{aligned}
                Cov(X, Y) &= E(XY) - E(X)E(Y) \\
                &= 1.8 - 2.07 \\
                &= -0.27 \not= 0, \\
            \end{aligned}
        \end{equation*}
        which means $X, Y$ are correlated.
    \subsection*{f}
        First, calculate standard variation of $X, Y$
        \begin{equation*}
            \begin{aligned}
                \sigma_{X} &= (E(X^{2}) - (E(X))^{2})^{1/2} \\
                &= (6.2 - 2.3^{2})^{1/2} \\
                &= foo \\
            \end{aligned}
        \end{equation*}
        \begin{equation*}
            \begin{aligned}
                \sigma_{Y} &= (E(X^{2}) - (E(X))^{2})^{1/2} \\
                &= (1.3 - 0.9^{2})^{1/2} \\
                &= bar \\
                \\
                r &= Cov(X, Y) / \sigma_{X}\sigma_{Y} \\
                &= foobar \\
            \end{aligned}
        \end{equation*}
    \subsection*{g}
        From the marginal pmf of Y, we have $P(Y < 1) = 0.3$, then the conditional pmf of $X$ can be calculated using $P_{X | Y < 1}(j) = P(j, Y < 1) / P(Y < 1)$, We have
        \begin{center}
            \begin{tabular}{| c | c | c | c | c | c |}
                \hline
                $j$  & 1 & 2 & 3 & 4 & otherwise\\
                \hline
                $P_{X | Y < 1}(j)$ & 1/3 & 1/3 & 0 & 1/3 & 0 \\
                \hline
            \end{tabular}
        \end{center}
    \subsection*{h}
        From the conditional pmf in $g$, the conditional expected value of $X$ is
        \begin{equation*}
            \begin{aligned}
                E(X | Y < 1) &= \sum_{j} j * P_{X | Y < 1}(j) \\
                &= 7/3 \\
            \end{aligned}
        \end{equation*}

\section*{Problem 2}
    \subsection*{a}
        From the joint pmf of $X, Z$, we have
        \begin{equation*}
            \begin{aligned}
                P_{X}(x) &= \sum_{z = x}^{+\infty} \frac{3^{z}}{x!(z - x)!} 0.4^{x} 0.6^{z - x} e^{-3} \\
                &= \frac{1.2^{x}}{x!} e^{-3} \sum_{t = 0}^{+\infty}  \frac{1.8^{t}}{t!}\quad (let\ t = z - x) \\
                &= \frac{1.2^{x}}{x!}e^{-1.2} \\
            \end{aligned}
        \end{equation*}
        It belongs to Poisson distribution with mean 1.2
    \subsection*{b}
        From the joint pmf of $X, Z$, we have
        \begin{equation*}
            \begin{aligned}
                P_{Z}(z) &= \sum_{x = 0}^{z} \frac{3^{z}}{x!(z - x)!} 0.4^{x} 0.6^{z - x} e^{-3} \\
                &= \frac{3^{z}}{z!}e^{-3} \sum_{x = 0}^{z} \frac{z!}{x!(z - x)!} 0.4^{x} 0.6^{z - x} \\
                &= \frac{3^{z}}{z!}e^{-3} \\
            \end{aligned}
        \end{equation*}
        It belongs to Poisson distribution with mean 3
    \subsection*{c}
        For $Z = X + Y$, we have
        \begin{equation}
            \begin{aligned}
                P_{Y}(y) &= \sum_{x = 0}^{+\infty} \frac{3^{x + y}}{x!y!} 0.4^{x} 0.6^{y} e^{-3} \\
                &= \frac{1.8^{y}}{y!} e^{-3} \sum_{x = 0}^{+\infty} \frac{3^{x}}{x!} 0.4^{x} \\
                &= \frac{1.8^{y}}{y!} e^{-1.8} \\
            \end{aligned}
        \end{equation}
        It belongs to Poisson distribution with mean 1.8
    \subsection*{d}
        No, a counterexample will be $(x, z) = (1, 0)$, for neither of $P_{X}(1), P_{Z}(0)$ equals zero, but by definition $P_{X, Z}(1, 0) = 0$
    \subsection*{e}
        Yes, for
        \begin{equation*}
            \begin{aligned}
                P_{X, Y}(x, y) &= P_{X, Z}(x, x + y)\quad (by\ definition) \\
                &= \frac{3^{x + y}}{x!((x + y) - x)!} 0.4^{x} 0.6^{(x + y) - x} e^{-3} \\
                &= \frac{3^{x + y}}{x!y!} 0.4^{x} 0.6^{y} e^{-3} \\
                &= \frac{1.2^{x}}{x!}e^{-1.2} \times \frac{1.8^{y}}{y!} e^{-1.8} \\
                &= P_{X}(x) \times P_{Y}(y) \\
            \end{aligned}
        \end{equation*}
    \subsection*{f}
        From the pmf of $X, Z$ and marginal pmf of $Z$, we have
        \begin{equation*}
            \begin{aligned}
                P_{X | Z}(x) &= (\frac{3^{z}}{x!(z - x)!} 0.4^{x} 0.6^{z - x} e^{-3}) / (\frac{3^{z}}{z!}e^{-3}) \\
                &= \frac{z!}{x!(z - x)!} 0.4^{x} 0.6^{z - x},
            \end{aligned}
        \end{equation*}
        which belongs to binomial distribution with paremeter $(n, p) = (z, 0.4)$.
    \subsection*{g}
        From the result in $(f)$, the conditional expectation of $X$ is $E[X | Z] = 0.4Z$.











\end{document}
